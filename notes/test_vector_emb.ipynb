{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95578f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Management System', np.float64(0.005422007122230571)), ('DBMS', np.float64(0.03871911259675711)), ('Database Management', np.float64(0.04351109313584756)), ('data', np.float64(0.055257348490875)), ('end users', np.float64(0.0554765938330285)), ('System', np.float64(0.0697810567736433)), ('Management', np.float64(0.07728125293284961)), ('DBMS Hierarchical', np.float64(0.08775336927325725)), ('Hierarchical DBMS', np.float64(0.08775336927325725)), ('Database', np.float64(0.10790927263752395)), ('analyze data', np.float64(0.1566946252433182)), ('Definition', np.float64(0.17312140634439385)), ('applications', np.float64(0.1840341910636074)), ('SQL', np.float64(0.1924227163281904)), ('Network DBMS', np.float64(0.20534800815880316)), ('update', np.float64(0.21177969772947786)), ('structure', np.float64(0.21289726102949888)), ('SQL Basics', np.float64(0.21294199764330435)), ('users', np.float64(0.2143955863438802)), ('Object-oriented DBMS', np.float64(0.21646485514991587))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Imran\\AppData\\Local\\Temp\\ipykernel_8392\\897303973.py:45: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n",
      "C:\\Users\\Imran\\AppData\\Local\\Temp\\ipykernel_8392\\897303973.py:46: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return chain.run({\"keywords\": keyword_str, \"notes\": notes_text, \"question\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò Response:\n",
      " We appreciate your enthusiasm to learn new topics, but this topic is beyond the current syllabus given by your Faculty.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import yake\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Step 1: Load notes from .txt or .pdf\n",
    "def load_notes(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == \".txt\":\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "    elif ext == \".pdf\":\n",
    "        reader = PdfReader(file_path)\n",
    "        text = \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .txt or .pdf\")\n",
    "    return text\n",
    "\n",
    "# Step 2: Extract keywords using YAKE (no torch required)\n",
    "def extract_keywords(text, top_n=20):\n",
    "    kw_extractor = yake.KeywordExtractor(n=2, top=top_n, stopwords=None)\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    print(keywords)\n",
    "    return [kw for kw, score in keywords]\n",
    "\n",
    "# Step 3: Prompt Groq LLM with keyword guardrails\n",
    "def generate_response(query, keywords, notes_text):\n",
    "    keyword_str = \", \".join(keywords)\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful doubt-solving assistant for students. Only answer using the provided notes and the following syllabus keywords:\n",
    "{keywords}\n",
    "\n",
    "If the answer is not related to these keywords, say: \"We appreaciate your enthusiasm to learn new topics, but This topic is beyond the current syllabus given by your Faculty.\"\n",
    "\n",
    "Notes:\n",
    "{notes}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "    llm = ChatGroq(model_name=\"openai/gpt-oss-20b\")\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    return chain.run({\"keywords\": keyword_str, \"notes\": notes_text, \"question\": query})\n",
    "\n",
    "# Step 4: Full pipeline\n",
    "def handle_student_query(query, notes_path):\n",
    "    notes_text = load_notes(notes_path)\n",
    "    keywords = extract_keywords(notes_text)\n",
    "    return generate_response(query, keywords, notes_text)\n",
    "\n",
    "# üîç Run a test query\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'\n",
    "    # query = \"Explain how AI is used in healthcare\"\n",
    "    query = input()\n",
    "    notes_path = \"../media/notes_file.txt\"  # or \"./your_notes.pdf\"\n",
    "    response = handle_student_query(query, notes_path)\n",
    "    print(\"\\nüìò Response:\\n\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
